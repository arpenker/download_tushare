# A股日线及30分钟K线数据同步工具

本项目是一个使用Python编写的工具，用于从Tushare Pro获取所有A股的日线及30分钟K线数据，并将其存储到本地的MySQL数据库中。

---

## 一键安装与启动

本项目专为Docker设计，可以极简地在您的Win10环境下运行。从零开始到服务启动，总共只需要**两条命令**。

**前提条件:**
- 已安装 [Git](https://git-scm.com/downloads)
- 已安装 [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/)

**步骤:**

**1. 下载项目**
打开您的命令行工具（如 PowerShell 或 CMD），进入您想存放项目的文件夹，然后运行以下命令从GitHub克隆项目：
```bash
git clone <项目在GitHub上的URL> A-stock-data-sync
cd A-stock-data-sync
```
*(注意: 请将 `<项目在GitHub上的URL>` 替换为实际的项目地址)*

**2. 配置并启动服务**
首先，将配置文件模板复制一份：
```bash
copy .env.example .env
```
然后，用记事本或其他编辑器打开 `.env` 文件，填入您的 `TUSHARE_TOKEN` 和一个自定义的数据库密码。

最后，运行以下命令来一键启动所有服务：
```bash
docker-compose up -d
```
服务启动后，您可以继续执行首次全量同步。详细说明请参考下面的“Docker一键部署”章节。

---

## 主要功能

- **多周期数据下载**: 一次性获取所有股票的历史日线和30分钟K线数据。
- **增量数据更新**: 每日定时任务，自动获取当天最新的日线和30分钟K线数据。
- **进度条显示**: 在进行大量数据下载时，提供清晰的进度条。
- **数据表自动创建**: 首次运行时可自动创建所需的数据库和数据表。
- **定时任务**: 内置一个基于APScheduler的定时任务，可在每个交易日收盘后自动执行增量更新。
- **灵活的命令行接口**: 支持通过命令行参数执行不同的任务。
- **Docker一键部署**: 提供`docker-compose`配置，实现自动化部署和静默运行。
- **健壮性设计**:
  - **API请求重试**: 网络请求失败时，会自动重试3次，提高同步成功率。
  - **数据自愈**: 每周日凌晨会自动执行数据完整性检查，并修复可能因网络问题等原因导致的数据空洞。

---

## Docker一键部署（详细说明）

本章节提供部署和使用的详细信息。

**1. 配置**

将项目根目录下的 `.env.example` 文件复制一份并重命名为 `.env`。然后打开 `.env` 文件，填入您的个人信息：

```
# .env
TUSHARE_TOKEN=YOUR_TUSHARE_TOKEN_HERE
MYSQL_ROOT_PASSWORD=your_strong_password
```
- `TUSHARE_TOKEN`: 您的Tushare Pro API Token。
- `MYSQL_ROOT_PASSWORD`: 为您的数据库设置一个安全的密码。

**2. 启动服务**

在项目根目录下，打开命令行工具（如 PowerShell 或 CMD），运行以下命令：
```bash
docker-compose up -d
```
该命令会做以下事情：
- 在后台构建并启动Python应用容器和MySQL数据库容器。
- 数据库会自动创建，数据会持久化存储在Docker卷中。
- Python应用会自动开始执行定时任务，在每个交易日下午16:00进行增量同步。

**3. 执行首次全量同步**

服务启动后，您需要手动执行一次统一的全量同步，来获取全部的历史数据（**该过程将先同步日线，后同步30分钟线**）。
打开一个新的命令行窗口，运行以下命令：

```bash
docker-compose exec app python main.py full_all
```
这个过程会非常耗时，请耐心等待。完成后，未来的数据将由定时任务自动增量同步。

**4. 日常使用**

- **查看日志**: 如果想观察程序的运行状态，可以查看应用日志。
  ```bash
  docker-compose logs -f app
  ```
- **连接数据库**: 您可以使用任何MySQL客户端（如Navicat, DataGrip, DBeaver）连接到数据库来查看和分析数据。
  - **主机**: `127.0.0.1`
  - **端口**: `3307` (注意，已映射到3307以避免与本地MySQL冲突)
  - **用户**: `root`
  - **密码**: 您在 `.env` 文件中设置的 `MYSQL_ROOT_PASSWORD`
  - **数据库**: `stock_data`

- **停止服务**: 如果您想停止所有服务，可以运行：
  ```bash
  docker-compose down
  ```

---

## 数据分析安全时间约定

为确保您在进行数据分析和计算时，不会与后台的数据同步任务发生冲突（例如读取到不完整的数据），我们约定以下时间窗口：

- **数据写入时间**:
  - **每日增量更新**: **周一至周五的 16:00** 开始，通常在几分钟内完成。
  - **每周数据修复**: **周日的 02:00** (凌晨2点) 开始，执行时间可能较长，取决于需要修复的数据量。

- **安全分析窗口**:
  - **交易日**: 建议在 **17:00 之后** 进行当天的分析和计算。
  - **周末**: **周六全天** 及 **周日03:00之后** 是绝对安全的时间。

**简而言之，只要避开每个交易日下午的4点和周日凌晨2点这两个时间点，您就可以随时安全地使用数据库中的数据。**

---

## 手动安装与使用（旧版）

如果您不想使用Docker，也可以按照传统方式手动部署。

### 环境要求

- Python 3.7+
- MySQL 5.7+ 或 MariaDB

### 安装与配置

(步骤省略，请参考Docker部署方式中的配置说明)

### 使用说明

**1. 初始化数据库表**
```bash
python main.py initdb
```

**2. 全量同步历史数据**
```bash
# 【推荐】一键同步所有数据
python main.py full_all

# 或者，分步同步
# python main.py full_daily
# python main.py full
```

**3. 增量更新数据**
```bash
# 增量更新30分钟线 (日线数据会自动在定时任务中更新)
python main.py update

# 增量更新日线
python main.py update_daily
```

**4. 运行定时任务**
```bash
# 这将同时更新30分钟线和日线数据
python scheduler.py
```
